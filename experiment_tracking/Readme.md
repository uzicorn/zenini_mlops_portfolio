# Experiment Tracking

## Description du projet
Je suis Data engineer sp√©cialis√© ELT/ETL et business analytics depuis 3 ans, je m'oriente en Machine learning Operations / IA Engineer.
Ce projet vise √† d√©montrer mes comp√©tences en **`experiment tracking`** au vue d'une candidature.

Il d√©montre mes expertises en :
- D√©ploiement automatis√© d'un serveur d'*experiment tracking* dans le cloud avec **MLflow**.
- Ingestion normalis√©e de donn√©es.
- Mise en place d'outils intuitifs pour les data scientists : `WebApp`, commandes `make`, et gestion de secrets.
- Configuration, d√©ploiement et utilisation de **MLflow** dans un contexte de data science.
- Devops : AWS DevOps / CloudFormation 


Pour plus de contexte sur mon parcours, consultez la section "Qui suis-je ?" en fin de ce README.

## Objectif du Projet

Ce projet vise √† illustrer un flux complet d'*experiment tracking* en MLOps, en simulant un environnement de production o√π plusieurs data scientists travaillent ensemble. 

Chaque data scientist est en mesure de : 
- D√©ployer la stack
- Ing√©rer les donn√©es en une commande
- D√©velopper des scripts d'entrainement
- Entrainer les mod√©les
- Tracker l'avancement global du projet **via une interface web**. 
## Structure du projet

Le projet est compos√© des √©l√©ments suivants :
- Une instance virtuelle sur **AWS EC2** pour h√©berger le serveur de `MlFlow`.
- Une base de donn√©es **PostgreSQL** sur **AWS RDS** pour stocker les m√©tadonn√©es des exp√©riences.
- Un module local d'ingestion de donn√©es, normalisant les datasets pour l'entra√Ænement.
- Un module d'entra√Ænement de mod√®les ML, int√©grant **MLflow** pour le logging.
- Une WebApp de tracking bas√©e sur **FastAPI**, d√©di√©e aux data scientists pour visualiser et interagir avec les exp√©riences en temps r√©el.
  
![alt text](experiment_tracking/readme_images/global_project.png)

### Screenshots 

**Stack d√©ploy√©e**
![alt text](experiment_tracking/readme_images/cloud_formation.png)

**connexion au EC2**
![alt text](experiment_tracking/readme_images/connect_ec2.png)

**Ingestion**
![alt text](experiment_tracking/readme_images/ingestion.png)

**Training**
![alt text](experiment_tracking/readme_images/training.png)

**Tracker / runs data**
![alt text](experiment_tracking/readme_images/tracker_1.png)

**Tracker / datasource**
![alt text](experiment_tracking/readme_images/tracker_2.png)


## Repository:
```bash
  .
  ‚îú‚îÄ‚îÄ experiment_tracking
  ‚îÇ   ‚îú‚îÄ‚îÄ .env                                   # Fichier d'environnement a rajouter manuellement, voir template plus bas. 
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ infra                                  # Fichiers de DevOps
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ config.toml
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ec2-init.sh
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ template.yaml
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ingestion                              # Scriptes d'ingestion
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ingest.py
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ iris.py
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ utils.py        
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py                             # Initialise le module
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ Makefile                                # Contient les commandes d'automatisation
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ readme_images                           # Propre au Readme
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ...
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ secret                                  # A rajouter manuellement
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ Keyname.pem
  ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ training                                # Scriptes d'entrainement (N'√©tant pas Data scientist, les scriptes sont triviaux)
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ train_iris_classification.py
  ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ utils.py
  ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ webapp                                  # WebApp sur FastApi
  ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ app.py
  ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __init__.py
  ‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ sql                                 # Les endpoints de l'API (1 requ√™te = 1 endpoint)
  ‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ artifacts.sql
  ‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data_sources.sql
  ‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ runs.sql
  ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ utils.py
  ‚îú‚îÄ‚îÄ Readme.md
  ‚îî‚îÄ‚îÄ requirements.txt                            # Librairies python

```

## Quick start

### Pr√©requis
Avant de lancer le tracking il vous faut : 
- Un port libre sur votre machine example: `8000` pour la web app. vous le metterez ensuite dans la variable `$WEBAPP_PORT`
- Une base de donn√©e RDS dont vous connaissez le `host` `username` et `password`
- Les ressources AWS suivantes
  
| Ressource            | Description                                                                 |
|----------------------|-----------------------------------------------------------------------------|
| AWS client `awsv2`   | Client AWS install√© et accessible via `awsv2` (version d√©finie dans requirements.txt). |
| `$INFRA_BUCKET`      | Bucket S3 utilis√© par AWS SAM.                                              |
| `$ARTIFACTS_BUCKET`  | Bucket S3 destin√© au stockage des artifacts.                                |
| Subnet ID            | Identifiant d‚Äôun subnet reli√© au VPC par d√©faut (ex. `subnet-1234frt5653`). |
| Security Group ID    | Identifiant d‚Äôun security group (ex. `sg-1234frt5653`).                     |
| EC2 Key Pair         | Cl√© EC2 enregistr√©e dans `./experiment_tracking/secret/$KEYNAME`.           |

  
### Configuration du Security group de l'EC2 et de la base de donn√©e

#### Security group : EC2
Son ID est d√©fini dans la variable `$EC2_SECURITY_GROUP` _par example `sg-0c439c4ee075e16b6`_

Il n'est pas cr√©√© par cloudformation car je pr√©f√©re les security groups dynamiques si on souhaite plus tard changer de r√©gles, ajouter ou filtrer des adresses IP etc..

**inbound rules** : Agents ext√©rieurs qui peuvent avoir acc√©s √† l'EC2 en dehors de son r√©seau local.
| Type | Port | IP Range | Description |
|------|------|----------|-------------|
| SSH  | 22   | Votre adresse IP | Permet √† `make connect_ec2` de se connecter √† la machine virtuelle via SSH en utilisant `./secret/$KEYNAME` |
| TCP  | 5000 | Votre adresse IP | Permet √† votre adresse IP de se connecter au webserver de MLFlow |

**outbound rules** : A quoi peut avoir acc√©s l'EC2 en dehors de son r√©seau local.
Donne un acc√©s ext√©rieur √† l'EC2
| Type |IP Range | Description |
|------|---------|-------------|
|HTTP|0.0.0.0/0 | Donne un acc√©s internet √† l'EC2 pour DL les librairies et acc√©der √† S3

#### Security group : RDS
La base de donn√©e existe *en dehors de cloudformation* pour des raisons de s√©curit√©. Quoi qu'il arrive √† la stack, les donn√©es sont persist√©s.

**inbound rules** : Qui peut requ√™ter la base de donn√©e ?
| Type | Port | Source | Description |
|------|------|--------|-------------|
| TCP  | 5432 | `$EC2_SECURITY_GROUP` | Permet √† l'EC2 (MLflow server) de se connecter √† la BD  |
| TCP  | 5432 | Votre adresse IP | Optionel : Vous permet de vous connecter localement √† la BD|


### Librairies Python
1- Dans un environnement virtuel sous **`python >= 3.8`**
```bash
    cd experiment_tracking
    pip install -r requirements.txt
```
2- Tester les commandes
```bash
    awsv2 --version
    sam --version
```
### Variables d'environnements
Cr√©er un fichier dans `./experiment_tracking/.env` et le peupler suivant le template suivant:

**_Note : A ce stade, vous ne connaissez pas encore EC2_PUBLIC_URL car la machine virtuelle n'existe pas encore_**

```conf
    #----------------
    # EC2 publuc IP |
    #----------------
    # Update EC2 publuc IP each new deployement
    EC2_PUBLIC_URL=     # Example : "13.39.162.164"

    #---------
    # Python |
    #---------
    # Point to "bin/python3.n" (n>=8) of your virtual env 
    PYTHON_INTERPRETER_PATH=/path/to/virtual_env/bin/python3.11

    #-----------
    # Postgres |
    #-----------
    host=example-database.abcdefghijklmnop.eu-west-3.rds.amazonaws.com
    dbname=postgres
    user=your_user
    password=admin
    port=5432
    RDS_INGESTION_SCHEMA=ingestion_schema_name

    #--------
    # infra |
    #--------
    MLFLOW_VERSION=2.17.2                       # Fixed, do not change it.
    INFRA_BUCKET=some_bucket_name               # Bucket name where AWS SAM create the stack build
    ARTIFACTS_BUCKET=some_other_bucket_name     # Bucket name where MlFlow will save the artifacts
    SUBNET_ID=subnet-xxxx                       # Subnet in which the EC2 will be deployed 
    SECURITY_GROUP_IDS=sg-xxxx                  # Security group linked with the EC2 machine
    KEYNAME=some_key_pair_name                  # KeyName name under "./secret/KEYNAME"
    WEBAPP_PORT=8000                            # Local port where the FastApi webapp will run
```
# Run project

- Step 1 : Deploy Architecture
```bash
    make deploy_archi 
```
A la fin du run, La commande retourne l'IP publique de l'instance EC2. voir [screenshot](https://github.com/uzicorn/mlops/blob/main/experiment_tracking/readme_images/cloud_formation.png)
- Step 2 : Remplir `EC2_PUBLIC_URL` dans `./experiment_tracking/.env`
- Step 3 : Lancer l'ingestion
```bash
    make ingest
```
- step 4: Lancer l'entrainement des mod√®les
```bash
    make train_iris_ingestion
```
- step 5: Lancer la web app
```bash
    make run_webapp
```

Sur votre navigateur, allez sur : 

- **http://127.0.0.1:`$WEBAPP_PORT`/backend/runs**

- **http://127.0.0.1:`$WEBAPP_PORT`/backend/data_source**

# Specificit√©s du projet

### Makefile
```yaml
### Makefile variables
WORKDIR: /path/to/mlops/experiment_tracking
ENVPATH: $(WORKDIR)/.env

### Infra 
build_sam: Build into infra/.aws-sam.  
deploy_sam: Deploy resources to the mlops-serverless CloudFormation stack.  
upload_init_script_to_s3: Resolve variables in infra/ec2-init.sh and upload to $INFRA_BUCKET/ec2-init.sh.  
deploy_infra: run upload_init_script_to_s3 -> build_sam -> deploy_sam.  

### Webapp
run_webapp: Run webapp in port $WEBAPP_PORT

### MLOps
connect_ec2: SSH to the EC2 instance using secret/$KEYNAME.  
ingest: Run ingestion.ingest.  
train_iris_classification`: Run training.train_iris_classification.  

### Cleanup
delete_mlflow_backend: Truncate MLflow backend tables in RDS.  
delete_mlflow_artifacts: Delete all artifacts in $ARTIFACTS_BUCKET. 
delete_mlflow_data: delete_mlflow_backend -> delete_mlflow_artifacts.  
hard-delete-stack: Delete the `mlops-serverless` stack and AWS SAM cache.  
clear_pycache`: Remove Python cache files.  
order66`: delete_mlflow_backend -> delete_mlflow_artifacts -> clear_pycache -> hard-delete-stack. 
```

### Ingestion (ELT)
- Le script d‚Äôingestion cr√©e des classes Python `Dataset`.
- Un `Dataset` est un ensemble de donn√©es d‚Äôentra√Ænement et de test extrait d‚Äôune source brute, avec des attributs fixes :
  - name : `String`
  - training_data : `Dataframe`
  - test_data : `Dataframe`

- Pour chaque source, un script *connecteur* (ex : ingestion/iris.py) cr√©e l‚Äôobjet `Dataset` selon la sp√©cification de la source, que ce soit un repo public, une API ou le r√©sultat d'un scrapping.
- √Ä chaque stockage dans l‚Äôentrep√¥t de donn√©es, la table `$RDS_INGESTION_SCHEMA.dataset_metadata` est compl√©t√©e avec les m√©tadonn√©es du `Dataset` :
  - Emplacement des tables train et test dans la base
  - Nom du dataset
  - Date d‚Äôingestion  

L‚Äôobjet `Dataset` garantit que *les donn√©es sont normalis√©es avant le stockage*.

**Exemple de connecteur** : ingestion/iris.py  
1. `iris.py` charge le dataset Iris depuis scikit-learn.  
2. Les colonnes sont renomm√©es (ex : `sepal length (cm)` ‚Üí `sepal_length_cm`).  
3. Les colonnes enti√®res sont converties en `float64` pour la compatibilit√© MLflow.  
4. Deux splits train/test sont cr√©√©s (80/20 et 75/25).  
5. `ingestion.py` appelle `load_data()` pour ins√©rer les datasets et les m√©tadonn√©es dans RDS.  

Tables g√©n√©r√©es dans le sch√©ma `mlops_schema` :  
- `iris_0_train`, `iris_0_test` (split 80/20)  
- `iris_1_train`, `iris_1_test` (split 75/25)  

### Entra√Ænement
`train_iris_classification.py` :
1. Charge les datasets train/test depuis RDS.  
2. Configure MLflow : niveau de log, URI du serveur de tracking (depuis `./experiment_tracking/.env`) et nom de l‚Äôexp√©rience.  
3. V√©rifie qu‚Äôaucun run n‚Äôest actif avant d‚Äôen d√©marrer un nouveau pour √©viter les conflits.  
4. Appelle la fonction g√©n√©rique `utils.classification_training` avec :  
   - `model_name` : nom de l‚Äôartifact enregistr√© dans `s3://$ARTIFACTS_BUCKET/<run_id>/<model_name>`.  
   - `train_df` / `test_df` : DataFrames charg√©s depuis `$RDS_INGESTION_SCHEMA`.  
   - `param_dict` : param√®tres scikit.  
   - `target_column` : colonne label.  
5. Entra√Æne, √©value et log les m√©triques ; sauvegarde les artifacts dans `$ARTIFACTS_BUCKET` si l‚Äôaccuracy > 0.8.

### Gestion des secrets sur le cloud
L'initialisation de la machine virtuelle EC2 n√©cessite des variables de connexion √† la base de donn√©e. 

J'ai profit√© du POC pour impl√©menter une id√©e qu'il ne m'aurait pas √©t√© possible de faire en production. 

Voir la documentation de l'impl√©mentation sur `infra/ec2-init.sh`

## √ßa marche pas !

### Probl√©mes fr√©quents 

A- Avez vous activ√© votre environnement virtuel ? `source /path/to/virtuel_env/bin/activate`

B- La commande `make train_iris_clasification` freeze : Avez vous copi√© la valeur de `$EC2_PUBLIC_URL` dans le .env apr√®s le deploiement ?

C- **Probl√®mes li√©s au r√©seau**

- Le serveur EC2 n‚Äôest pas accessible via **http://`$EC2_PUBLIC_URL`:5000/#/**

    - **Cas 1 : Impossible de se connecter √† l‚ÄôEC2 avec `make connect_ec2`**  
      ‚Üí V√©rifier que votre adresse IP est bien autoris√©e dans le security group de l‚ÄôEC2 pour le port 22  
        (voir **security groups / EC2 / inbound_rules**).

    - **Cas 2 : Connexion SSH OK, mais rien ne tourne sur le port 5000 (serveur MLflow)**  
        - V√©rifier que MLflow est install√© :  
          ```bash
            mlflow --version
          ```
            - **Si MLflow est install√©** :  
              L‚ÄôEC2 n‚Äôa probablement pas acc√®s √† la base de donn√©es.  
              V√©rifier que le security group de l‚ÄôEC2 est bien autoris√© dans l‚Äôinbound rule du RDS pour le port 5432  
              (voir **security groups / RDS / inbound_rules**).

            - **Si MLflow n‚Äôest pas install√©** :  
              V√©rifier que `ec2-init.sh` est pr√©sent :  
              ```bash
              cat ../../ec2-init.sh
              ```
              - S‚Äôil manque :  
                Le script n‚Äôa pas √©t√© r√©cup√©r√© depuis le bucket `$INFRA_BUCKET`.  
                V√©rifier que l‚ÄôEC2 poss√®de une outbound rule lui permettant d‚Äôacc√©der √† Internet (et donc au bucket S3).
                Faites tourner `make order66` puis refaire les √©tapes du chapitre Run project


## üë§ Author

ZENINI SALIM  
zenini.salim@gmail.com  
07 56 13 48 52
Created as a portfolio project to demonstrate MLOps fundamentals on MLflow and AWS.

ZENINI SALIM
